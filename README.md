# Visual transformer for MNIST handwriting digit classification 

- Here is a short explanation of how we can use a neural network based on the transformer architecture trained on a handwritten digit dataset to classify handwritten digits:

1. We first break down the handwritten digit image into patches.
2. We then pass the embedded patches to the transformer architecture.
3. The transformer architecture learns long-range dependencies between the patches.
4. The output of the transformer architecture is a vector that represents the handwritten digit image.
5. We then use a classifier to predict the digit that the handwritten digit image represents.

![image](https://github.com/PanithanS/Visual-Transformer-MNIST/assets/83627892/f665f873-8411-47eb-bf3f-994432b4efa3)

# Prediction output

![image](https://github.com/PanithanS/Visual-Transformer-MNIST/assets/83627892/7b9b689c-195d-4231-a6c5-c0a9f74fc042)
